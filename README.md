# ðŸ§  Local LLM-Powered Data Assistant for Public Health (Wayne County Project)

## Overview
A privacy-preserving, offline AI assistant built using [LangChain](https://www.langchain.com/), [Ollama](https://ollama.com/), and [LLaMA 3](https://llama.meta.com/llama3) to enable natural language queries over sensitive human services datasets, including Fee and Residential data. This project was developed during my internship at the **Wayne County Health, Human & Veterans Services (HHVS)** department.

## ðŸ”§ Features
- âœ… Query structured CSV data using natural language
- ðŸ”’ Fully offline, privacy-respecting architecture (no cloud dependencies)
- ðŸ“„ Dynamic routing between multiple datasets
- ðŸ§  Model flexibility â€“ supports LLaMA 3, GPT, and Copilot (can be swapped)
- ðŸ“Š Built-in analytics â€“ count missing values, calculate averages, filter by dates, etc.
- ðŸ’¡ Extendable â€“ can be enhanced with memory, chatbot interface, and RAG

## ðŸ—‚ Datasets Used
- `Fee.csv` â€“ Client-level service data
- `Residential.csv` â€“ Records of residential placements
- `Dictionary.csv` â€“ Column descriptions for interpretability
- `Client.csv` â€“ Demographic and identifying info

## ðŸš€ Tech Stack
- Python + Pandas
- LangChain (Agents + Tools)
- Ollama (for local LLM running LLaMA 3)
- Terminal-based Q&A interface
- Optional: Streamlit frontend (future step)

## ðŸ“¸ Demo 


https://github.com/user-attachments/assets/154e0113-e3cb-4741-a493-cc1cacda1a1c


## ðŸ”„ Future Work
- Integrate **retrieval-augmented generation (RAG)** with data dictionary
- Add **memory and chat history**
- Deploy a **web-based chatbot interface** (e.g., using Streamlit or Gradio)
- Support **multiple model backends** (Copilot, GPT-4, Claude)
